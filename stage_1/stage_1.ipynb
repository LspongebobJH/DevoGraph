{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(\"/Users/watarukawakami/GSoC/DevoGraph\")\n",
    "sys.path.append(\"/Users/watarukawakami/GSoC/devolearn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import devolearn\n",
    "from pathlib import Path\n",
    "DATAPATH = Path('/Users/watarukawakami/GSoC/DevoGraph/data')\n",
    "\n",
    "from copy import deepcopy\n",
    "from importlib import reload\n",
    "# import devograph.datasets.datasets as data\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from devolearn import cell_membrane_segmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# didn't work\n",
    "# segmentor = cell_membrane_segmentor()\n",
    "#df = segmentor.predict_from_video(video_path = str(DATAPATH / \"EPIC_raw/20081016_alr-1_10A2_3_L1.mov\"), centroid_mode = True, save_folder = os.path.join(DATAPATH, \"preds\"))\n",
    "#df = segmentor.predict_from_video(video_path = str(DATAPATH / \"EPIC_raw/sm01.mov\"), centroid_mode = True, save_folder = os.path.join(DATAPATH, \"preds\"))\n",
    "#df = segmentor.predict_from_video(video_path = str(DATAPATH / \"EPIC_raw/sm01.mov\"), centroid_mode = True, save_folder = os.path.join(DATAPATH, \"preds\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sample_data of devolearn's cell_membrane_segmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "saving predictions:   0%|          | 0/421 [00:00<?, ?it/s][W NNPACK.cpp:80] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "saving predictions: 100%|██████████| 421/421 [01:44<00:00,  4.02it/s]\n"
     ]
    }
   ],
   "source": [
    "# worked\n",
    "\"\"\"\n",
    "sample_data = Path('/Users/watarukawakami/GSoC/DevoGraph/data/devo_learn/sample_data/')\n",
    "segmentor = cell_membrane_segmentor()\n",
    "df = segmentor.predict_from_video(video_path = str(sample_data / \"videos/seg_sample.mov\"), centroid_mode = True, save_folder = os.path.join(DATAPATH, \"preds\"))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"centroids.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "pic should be Tensor or ndarray. Got <class 'NoneType'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/watarukawakami/GSoC/DevoGraph/stage_1/stage_1.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/watarukawakami/GSoC/DevoGraph/stage_1/stage_1.ipynb#ch0000009?line=1'>2</a>\u001b[0m sample_data \u001b[39m=\u001b[39m Path(\u001b[39m'\u001b[39m\u001b[39m/Users/watarukawakami/GSoC/DevoGraph/data/devo_learn/sample_data/\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/watarukawakami/GSoC/DevoGraph/stage_1/stage_1.ipynb#ch0000009?line=2'>3</a>\u001b[0m segmentor \u001b[39m=\u001b[39m cell_nucleus_segmentor()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/watarukawakami/GSoC/DevoGraph/stage_1/stage_1.ipynb#ch0000009?line=3'>4</a>\u001b[0m image, centroids \u001b[39m=\u001b[39m segmentor\u001b[39m.\u001b[39;49mpredict(image_path \u001b[39m=\u001b[39;49m \u001b[39mstr\u001b[39;49m(sample_data \u001b[39m/\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mimages/nucleus_seg_sample.jpg\u001b[39;49m\u001b[39m\"\u001b[39;49m), centroid_mode \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/GSoC/devolearn/devolearn/cell_nucleus_segmentor/cell_nucleus_segmentor.py:131\u001b[0m, in \u001b[0;36mcell_nucleus_segmentor.predict\u001b[0;34m(self, image_path, pred_size, centroid_mode)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[39mLoads an image from image_path and converts it to grayscale,\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39mthen passes it through the model and returns centroids of the segmented features.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m \n\u001b[1;32m    128\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    130\u001b[0m im \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(image_path,\u001b[39m0\u001b[39m)\n\u001b[0;32m--> 131\u001b[0m tensor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpreprocess(im)\n\u001b[1;32m    132\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(tensor)\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[1;32m    133\u001b[0m res \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mresize(res,pred_size)\n",
      "File \u001b[0;32m~/GSoC/devolearn/devolearn/cell_nucleus_segmentor/cell_nucleus_segmentor.py:110\u001b[0m, in \u001b[0;36mcell_nucleus_segmentor.preprocess\u001b[0;34m(self, image_grayscale_numpy)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpreprocess\u001b[39m(\u001b[39mself\u001b[39m, image_grayscale_numpy):\n\u001b[0;32m--> 110\u001b[0m     tensor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmini_transform(image_grayscale_numpy)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    111\u001b[0m     \u001b[39mreturn\u001b[39;00m tensor\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/devolearn/lib/python3.8/site-packages/torchvision/transforms/transforms.py:67\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[1;32m     66\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m---> 67\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[1;32m     68\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/devolearn/lib/python3.8/site-packages/torchvision/transforms/transforms.py:185\u001b[0m, in \u001b[0;36mToPILImage.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[1;32m    177\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[39m        pic (Tensor or numpy.ndarray): Image to be converted to PIL Image.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    183\u001b[0m \n\u001b[1;32m    184\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mto_pil_image(pic, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/devolearn/lib/python3.8/site-packages/torchvision/transforms/functional.py:176\u001b[0m, in \u001b[0;36mto_pil_image\u001b[0;34m(pic, mode)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39m\"\"\"Convert a tensor or an ndarray to PIL Image.\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \n\u001b[1;32m    164\u001b[0m \u001b[39mSee :class:`~torchvision.transforms.ToPILImage` for more details.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39m    PIL Image: Image converted to PIL Image.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m(\u001b[39misinstance\u001b[39m(pic, torch\u001b[39m.\u001b[39mTensor) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(pic, np\u001b[39m.\u001b[39mndarray)):\n\u001b[0;32m--> 176\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mpic should be Tensor or ndarray. Got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(pic)))\n\u001b[1;32m    178\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(pic, torch\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m    179\u001b[0m     \u001b[39mif\u001b[39;00m pic\u001b[39m.\u001b[39mndimension() \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m {\u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m}:\n",
      "\u001b[0;31mTypeError\u001b[0m: pic should be Tensor or ndarray. Got <class 'NoneType'>."
     ]
    }
   ],
   "source": [
    "from devolearn import cell_nucleus_segmentor\n",
    "sample_data = Path('/Users/watarukawakami/GSoC/DevoGraph/data/devo_learn/sample_data/')\n",
    "segmentor = cell_nucleus_segmentor()\n",
    "image, centroids = segmentor.predict(image_path = str(sample_data / \"images/nucleus_seg_sample.jpg\"), centroid_mode = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "saving predictions: 100%|██████████| 236/236 [00:59<00:00,  3.94it/s]\n"
     ]
    }
   ],
   "source": [
    "from devolearn import cell_nucleus_segmentor\n",
    "segmentor = cell_nucleus_segmentor()\n",
    "df = segmentor.predict_from_video(video_path = str(DATAPATH / \"EPIC_raw/20081016_alr-1_10A2_3_L1.mov\"), centroid_mode = True, save_folder = os.path.join(DATAPATH, \"preds\"))\n",
    "#plt.imshow(seg_pred)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"centroids.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('devolearn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7b055c650a23e3c12e587422c81df7086a216aad35f563f3feb44dcd655a832"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
